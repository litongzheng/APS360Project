{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d27d1bcc69ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_text = \"\"\n",
    "\n",
    "chars = []\n",
    "i = 0\n",
    "for char in open('character.txt'):\n",
    "    chars.append(char.strip() + \":\\t\")\n",
    "    if i>=300:\n",
    "        break\n",
    "    i = i+1\n",
    "lines = [] \n",
    "\n",
    "i = 0\n",
    "for line in open('line.txt'):\n",
    "        lines.append(line)\n",
    "        if i>=300:\n",
    "            break\n",
    "        i = i+1\n",
    "        \n",
    "for i in range(len(lines)):\n",
    "    total = chars[i] + lines[i]\n",
    "    sp_text += total\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk(chunk_len=300):\n",
    "    \"\"\"Return a random subsequence from `spam_text`\"\"\"\n",
    "    start_index = random.randint(0, cartman_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return cartman_text[start_index:end_index]\n",
    "\n",
    "def text_to_tensor(text, vocab=vocab):\n",
    "    \"\"\"Return a tensor containing the indices of characters in `text`.\"\"\"\n",
    "    indices = [vocab_stoi[ch] for ch in text]\n",
    "    return torch.tensor(indices)\n",
    "\n",
    "# def random_training_set(chunk_len=300):    \n",
    "#     chunk = random_chunk(chunk_len)\n",
    "#     inp = text_to_tensor(chunk[:-1])   # omit the last token\n",
    "#     target = text_to_tensor(chunk[1:]) # omit the first token\n",
    "#     return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## batching???\n",
    "## from someone else on github\n",
    "import numpy as np\n",
    "def get_batches(words, sequence_length):\n",
    "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
    "    \n",
    "    ## code starts: \n",
    "    len_of_texts = len(words) \n",
    "    #batch_x = []\n",
    "    #batch_y = []\n",
    "    feature_batches = []\n",
    "    target_batches = []\n",
    "    for i in range(len_of_texts):\n",
    "            ##batch * stride + item * batch_size * sequence_length, with stride = 1\n",
    "            begin_x = i\n",
    "            end_x = begin_x + sequence_length\n",
    "            if end_x < len_of_texts - 1:\n",
    "                position_y = end_x + 1\n",
    "                #print(\"begin_x = \", begin_x)\n",
    "                #print(\"end_x = \", end_x)\n",
    "                #print(\"position_y = \", position_y)\n",
    "                #batch_x = words[begin_x:end_x]\n",
    "                #batch_y = words[position_y]\n",
    "                feature_batches.append(words[begin_x:end_x])\n",
    "                target_batches.append(words[position_y-1])\n",
    "    return np.array(feature_batches), np.array(target_batches)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def batch_data(words, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param words: The word ids of the TV scripts\n",
    "    :param sequence_length: The sequence length of each batch\n",
    "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    ## get the batches contain sequence lengths of data    \n",
    "    feature_tensor, target_tensor = get_batches(words, sequence_length)\n",
    "    data = TensorDataset(torch.from_numpy(feature_tensor), torch.from_numpy(target_tensor))\n",
    "    data_loader = torch.utils.data.DataLoader(data, shuffle=True, batch_size=batch_size)\n",
    "    # return a dataloader\n",
    "    return data_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
